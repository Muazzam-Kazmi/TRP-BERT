{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TRP-BERT_Feature_generation_and_model_loading_BERT_Large_Cased.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UOJBddQWj3f"
      },
      "source": [
        "# ***Classification of TRP Channels from Non-TRP Channels***\n",
        "***20480 features for BERT Large Cased***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8VO0ZTB8Bal",
        "outputId": "cea5fb9e-0dba-41ed-e0ac-842133793e95"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyyaGiefC-5y"
      },
      "source": [
        "# **Check IF 12GB memory of GPU is shared with other users**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj9hgCpmDDAq",
        "outputId": "50ad10f2-ad26-4e63-9bc0-6d0dd023a482"
      },
      "source": [
        "# Memory footprint support libraries/code\n",
        "# If in case, the utilization is greater than 0% try to kill using the code (!kill -9 -1). \n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=ba599eaeda97a205ce979df47bcd67f0a65ccc5251fa1a69fa1b964575880b67\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 118.6 MB\n",
            "GPU RAM Free: 15109MB | Used: 0MB | Util   0% | Total 15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRk9DvTRLZjP"
      },
      "source": [
        "# **Load Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vtzz9ZQLcfM"
      },
      "source": [
        "import pandas as pd \n",
        "import time\n",
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F48HSf7Wq_K"
      },
      "source": [
        "# **Partition the protein sequence into subparts of length**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC7iv549HGAL"
      },
      "source": [
        "# Cut string to list\n",
        "def cut_string(input_str, x):\n",
        "    # Cut\n",
        "    lst_res = [input_str[y-x:y] for y in range(x, len(input_str)+x, x)]\n",
        "    return lst_res;"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms9PFAryYuqr"
      },
      "source": [
        "# **Generate N-gram**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlEWgmx5YyL0"
      },
      "source": [
        "# CREATE N-GRAMS DATA\n",
        "\n",
        "'''\n",
        " A function to split the data into n-gram feature\n",
        "'''\n",
        "def ngrams(input, n):\n",
        "  # Cut string the same with BERT max input 512\n",
        "  if len(input) < 510:\n",
        "    input = input[0:len(input)];\n",
        "  else:\n",
        "    input = input[0:510];\n",
        "  \n",
        "  # Create a list and dataframe\n",
        "  output = []\n",
        "\n",
        "  # loop for each residues (+1 needs max the loop)\n",
        "  for i in range(0, (len(input)+1)-n): # minus n means stop at final string\n",
        "      # Cut for each n-gram\n",
        "      g = input[i:i+n];\n",
        "\n",
        "      # Score in list\n",
        "      output.append(g);\n",
        "\n",
        "  # Convert list to string\n",
        "  joinstr = ' '.join(output);\n",
        "\n",
        "  return joinstr;"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1uLQbWudHWH"
      },
      "source": [
        "# **Installation/clone Bert**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHyhWgdLdL50",
        "outputId": "e79cf457-7d47-49c7-d0a2-03320560d46d"
      },
      "source": [
        "import sys\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 328.28 KiB | 2.88 MiB/s, done.\n",
            "Resolving deltas: 100% (182/182), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6NF_VAG4fJn",
        "outputId": "9b55b78b-8f64-4091-eb59-bd5b95e340d3"
      },
      "source": [
        "# Download bert model\n",
        "# BERT-Large, Uncased: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 04:09:44--  https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.128, 2607:f8b0:4023:c0b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1242178883 (1.2G) [application/zip]\n",
            "Saving to: ‘cased_L-24_H-1024_A-16.zip’\n",
            "\n",
            "cased_L-24_H-1024_A 100%[===================>]   1.16G  71.3MB/s    in 14s     \n",
            "\n",
            "2021-06-05 04:09:59 (82.9 MB/s) - ‘cased_L-24_H-1024_A-16.zip’ saved [1242178883/1242178883]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLFQvtyGFQ2S"
      },
      "source": [
        "# **Extract/unzip BERT Large Cased model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzFww9CG4u8u"
      },
      "source": [
        "# Extract all files\n",
        "import zipfile\n",
        "\n",
        "folder = 'model_folder'\n",
        "with zipfile.ZipFile(\"cased_L-24_H-1024_A-16.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(folder)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYV9Q_nodJdk",
        "outputId": "61de9fe5-11fe-4dec-a2d2-874821869f38"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.2\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import run_classifier_with_tfhub\n",
        "import tokenization\n",
        "import tensorflow as tf\n",
        "# import tfhub \n",
        "import tensorflow_hub as hub\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==1.15.2 in /usr/local/lib/python3.7/dist-packages (1.15.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.34.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.7.4.3)\n",
            "WARNING:tensorflow:From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ28EKx5eNTG"
      },
      "source": [
        "# **Get embeddings for input data files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFGPfnC9iv0L"
      },
      "source": [
        "# Calculate a logistic sigmoid function\n",
        "# def sigmoid(x):\n",
        "#   return 1 / (1 + math.exp(-x))\n",
        "data_bert_new = pd.DataFrame()\n",
        "# Extract features for n-gram embeddings\n",
        "def extractFeatureEmbedingJSONL(input_jsonl_file_path):\n",
        "  # Temporary store variable\n",
        "  temp_store_feature = [];\n",
        "  embedding = []\n",
        "  # Read JSONL files and append embedding vectors\n",
        "  with open(input_jsonl_file_path) as f:\n",
        "      for line in f:\n",
        "        embedding.append(json.loads(line))\n",
        "  # Print total rows data in test and train\n",
        "  #print(\"Max embedings: \"+str(len(embedding)))\n",
        "    \n",
        "  # Extract feature for each proteins here\n",
        "  for row_index, get_prot_embedding in enumerate(embedding):\n",
        "    # Temp variables\n",
        "    store_token_amino_acid = [];\n",
        "    store_token_embedding = [];\n",
        "  \n",
        "    # Get features\n",
        "    features = embedding[row_index][\"features\"]\n",
        "    # print('features')\n",
        "    # print(features)\n",
        "\n",
        "    # Extract amino acid tokens and vectors (token embedding)\n",
        "    for index, feature in enumerate(features):\n",
        "      token_amino_acid = feature[\"token\"]\n",
        "      # Order from original paper about layer ([\"layers\"] [\"index\"] [\"values\"])\n",
        "      # Index mens index of layer, ':' means select all layers\n",
        "      token_embedding_layer0 = feature[\"layers\"][0][\"values\"] # Sum last 4 layers\n",
        "      token_embedding_layer1 = feature[\"layers\"][1][\"values\"] # Sum last 4 layers\n",
        "      token_embedding_layer2 = feature[\"layers\"][2][\"values\"] # Sum last 4 layers\n",
        "      token_embedding_layer3 = feature[\"layers\"][3][\"values\"] # Sum last 4 layers\n",
        "      \n",
        "      # # Make list in list for all four layers\n",
        "      # token_embedding = [token_embedding_layer0, token_embedding_layer1, token_embedding_layer2, token_embedding_layer3];\n",
        "\n",
        "      # Take only last (-1) layer for each token\n",
        "      token_embedding = token_embedding_layer0;\n",
        "      # print(token_embedding)\n",
        "\n",
        "  #     # Sum last 4 layers (sum of the last four layers)\n",
        "  #     token_embedding = sum(map(np.array, token_embedding));\n",
        "  #     # print(token_embedding);\n",
        "  #     #print(token_amino_acid);\n",
        "      \n",
        "      # Store\n",
        "      store_token_amino_acid.append(token_amino_acid);\n",
        "      store_token_embedding.append(token_embedding);\n",
        "\n",
        "  #     #print(f\"{index}. token amino acid: {token_amino_acid}\")\n",
        "  #     #print(f\" Protein embedding: {token_embedding[:]}\")\n",
        "  #     #print(\"\\n\")\n",
        "\n",
        "  #   # Convert to dataframe (look like PSSM)\n",
        "    data_bert = pd.DataFrame(store_token_embedding)\n",
        "\n",
        "  #   # Add amino acid in dataframe\n",
        "    data_bert['residue'] = store_token_amino_acid # Creat a new column represents all amino acids\n",
        "    # Remove first and last rows containing special tokens\n",
        "    data_bert = data_bert.drop(data_bert.index[len(data_bert)-1])\n",
        "    data_bert = data_bert.drop(data_bert.index[0])\n",
        "    return data_bert;"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMVQM72BGP0w"
      },
      "source": [
        "#**Generate Matrix fro BERT representations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "035Rrz6cgdTR"
      },
      "source": [
        "def GenerateBERTEmbeddingMatrix(df_protein_bert_embeddings):\n",
        "  # Put all amino acids in order to know missing column 20 amino acid\n",
        "  # default_AA = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
        "  default_AA = ['a','c','d','e','f','g','h','i','k','l','m','n','p','q','r','s','t','v','w','y']\n",
        "\n",
        "  # Sum/mean multiple row values of various columns grouped by 'residue'\n",
        "  df_protein_bert_embeddings = df_protein_bert_embeddings.groupby('residue', as_index=False).sum()\n",
        "  print(df_protein_bert_embeddings)\n",
        "  # res_values = data_bert.groupby('residue', as_index=False).mean()\n",
        "  # print(df_protein_bert_embeddings)\n",
        "\n",
        "  # Transpose first row as header\n",
        "  df_protein_bert_embeddings = df_protein_bert_embeddings.set_index('residue').T\n",
        "  # print(df_protein_bert_embeddings)\n",
        "\n",
        "  # Get recent column names \n",
        "  get_column_names = df_protein_bert_embeddings.columns.tolist()\n",
        "  # print(get_column_names)\n",
        "  # print(default_AA)\n",
        "  \n",
        "  # Check all columns are exist\n",
        "  get_column_mis = list(set(default_AA).difference(get_column_names))\n",
        "  # print(get_column_mis)\n",
        "\n",
        "  # Check list \n",
        "  if   len(get_column_mis) > 0:\n",
        "    for get_aa in get_column_mis:\n",
        "      # Create column with value 0\n",
        "      df_protein_bert_embeddings[get_aa] = 0;\n",
        "\n",
        "  # Select only default amino acids\n",
        "  bert_values_order = df_protein_bert_embeddings[default_AA]\n",
        "  # print(bert_values_order)\n",
        "\n",
        "  # 6. Transpose again\n",
        "  bert_values_order = bert_values_order.transpose()\n",
        "\n",
        "  # 7. Change the idea like PSSM (We used all 20 rows × 3072 columns matrix)\n",
        "  # ##############################################################################\n",
        "  # Change the idea like PSSM (We used all 20 rows × 3072 columns matrix)\n",
        "  # It means that we will generate more than 61441 features for each proteins\n",
        "  # ##############################################################################\n",
        "  # Pandas flatten a dataframe to a list (use .flatten() on the DataFrame)\n",
        "  bert_feature_used = bert_values_order.values.flatten();\n",
        "\n",
        "  return bert_feature_used\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkboBZa-eXU-"
      },
      "source": [
        "# Note: Auto detect for GPU when set use_tpu=False (training will fall on CPU or GPU)\n",
        "# From the jsonl file you have last 4 layers outputs or -1,-2,-3,-4\n",
        "# Get embeddings for input data classifiers from Google Colab terminal command\n",
        "def extractEmbeddingBertFeatures(df_data, bert_model_path='cased_L-24_H-1024_A-16'): \n",
        "    start_time = time.time()\n",
        "    get_path = bert_model_path;\n",
        "    print(\"Bert Path: {0}\".format(get_path));\n",
        "\n",
        "    # Save temp dataframe and run bert embedding extractor\n",
        "    df_data.to_csv('input.txt', index=False, header=False, quoting=csv.QUOTE_NONE)\n",
        "    os.system(f\"python3 /content/bert_repo/extract_features.py \\\n",
        "               --input_file=input.txt \\\n",
        "               --output_file=output.jsonl \\\n",
        "               --vocab_file='{bert_model_path}/vocab.txt' \\\n",
        "               --bert_config_file='{bert_model_path}/bert_config.json' \\\n",
        "               --init_checkpoint='{bert_model_path}/bert_model.ckpt' \\\n",
        "               --layers='-1,-2,-3,-4' \\\n",
        "               --max_seq_length=512 \\\n",
        "               --do_lower_case=True \\\n",
        "               --batch_size=8 \\\n",
        "               --use_tpu=False\")\n",
        "\n",
        "    #bert_output = pd.read_json(\"output.jsonl\", lines=True)\n",
        "    #bert_output.head()\n",
        "    \n",
        "    # Call function and extract/genereate all bert features from embedding files\n",
        "    result_features = extractFeatureEmbedingJSONL('output.jsonl');\n",
        "\n",
        "    # Remove temp files\n",
        "    os.system(\"rm input.txt\")\n",
        "    os.system(\"rm output.jsonl\")\n",
        "    \n",
        "    #Convert to dataframe\n",
        "    df_results = pd.DataFrame(result_features)\n",
        "    \n",
        "    # Timing\n",
        "    print(\"[It takes {0} seconds to extract embedding features]\".format((time.time() - start_time)))\n",
        "\n",
        "    return result_features  "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQbm0LnGGi0a"
      },
      "source": [
        "#**LOOP DATA FOR EACH PROTEINS & BERT PATH SETTING**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7EOVCpWYMhU"
      },
      "source": [
        "###############################################################################\n",
        "# LOOP DATA FOR EACH PROTEINS & BERT PATH SETTINGS\n",
        "# BECAUSE MAX LENGHT IS 510 (512), SO REPEATE THE PROCESS APPEND DATAFRAME LATER\n",
        "###############################################################################\n",
        "\n",
        "def generate_portionwise_embeddings(df_fasta_format):\n",
        "  df_final_results = pd.DataFrame()\n",
        "  bert_store_feature = [];\n",
        "  bert_prot_id = [];\n",
        "  for index, row in df_fasta_format.iterrows():\n",
        "    df_selected = df_fasta_format.iloc[index:index+1 , : ]; # for each row\n",
        "    str_sequence = df_selected['SEQUENCE'].tolist()[0];\n",
        "  # Split to max 510 amino acids (with 2 additional special tokens)\n",
        "    lst_part_seq = cut_string(str_sequence, 510);\n",
        "    # print(lst_part_seq)\n",
        "    get_id = df_selected['ID'].tolist()[0];\n",
        "  # #  Create dataframe for each proteins ID\n",
        "    df_prot = pd.DataFrame({\"SEQUENCE\": lst_part_seq, 'ID': get_id})\n",
        "  # # #   CREATE N-GRAMS DATA\n",
        "    df_prot['1-grams'] = df_prot.apply(lambda x: ngrams(x['SEQUENCE'], 1), axis=1)\n",
        "    df_bert_res_new = pd.DataFrame()\n",
        "    # print(df_prot['1-grams']);\n",
        "    for subsequence in df_prot['1-grams'].values.tolist():\n",
        "      df_unigram = pd.DataFrame({subsequence})\n",
        "      df_unigram = df_unigram.rename(columns = {0: \"unigram\"})\n",
        "      # print(df_unigram['unigram'][0]);\n",
        "      BERT_PRETRAINED_DIR = '/content/model_folder/cased_L-24_H-1024_A-16' \n",
        "      print('>>  BERT pretrained directory: '+BERT_PRETRAINED_DIR)\n",
        "      print(\"SUBSEQUENCE OF PROTEINS:\");print(subsequence);\n",
        "      df_bert_res_return = extractEmbeddingBertFeatures(df_unigram, BERT_PRETRAINED_DIR);\n",
        "      print(df_bert_res_return)\n",
        "\n",
        "      df_bert_res_new = df_bert_res_new.append(df_bert_res_return)\n",
        "      df_bert_res_new.reset_index(drop=True, inplace=True)\n",
        "      \n",
        "    print(\"All BERT EMBDDING BEFORE CALCULATIONS:\");\n",
        "    print(df_bert_res_new);  \n",
        "    \n",
        "    # Simple method to calcuate bert feature for classifiers\n",
        "    bert_feature_flattened = GenerateBERTEmbeddingMatrix(df_bert_res_new)\n",
        "    print(bert_feature_flattened)\n",
        "    \n",
        "    # Store for all proteins in list with their ID\n",
        "    bert_store_feature.append(bert_feature_flattened);\n",
        "    bert_prot_id.append(get_id);\n",
        "\n",
        "  df_results = pd.DataFrame(bert_store_feature)\n",
        "  df_results ['ID'] = bert_prot_id;\n",
        "\n",
        "  return df_results"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsNgwOadG3cw"
      },
      "source": [
        "#**Read Fasta Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_nFYk33Qboh"
      },
      "source": [
        "def read_fasta_input(fastaSequenceInput):\n",
        "    # Variables\n",
        "    store_accesion_id = [];\n",
        "    store_sequence_prot = [];\n",
        "    store_seq_Length = [];\n",
        "    \n",
        "    data = fastaSequenceInput.replace('\\n\\n', '\\n');\n",
        "    getProtSeq = data.split(\">\")\n",
        "    str_list = list(filter(None, getProtSeq)) # fastest\n",
        "    \n",
        "    for data_lst in str_list:\n",
        "        try:\n",
        "            each_prot = data_lst.split(\"\\n\")\n",
        "            clear_prot = list(filter(None, each_prot)) # fastest\n",
        "            # Get ID by first index and set to lowercase\n",
        "            accesion_id = clear_prot[0];\n",
        "            # Get sequence of protein by joining list from index\n",
        "            get_sequence = \"\".join(clear_prot[1:len(clear_prot)]);\n",
        "            get_sequence = get_sequence.replace('  ', ' ').replace(' ', '').replace('\\t', '').replace('\\n', '').replace('<br>', '');\n",
        "            # Get sequence length\n",
        "            get_seq_len = len(get_sequence);\n",
        "            # Store\n",
        "            store_accesion_id.append(accesion_id);\n",
        "            store_sequence_prot.append(get_sequence);\n",
        "            store_seq_Length.append(get_seq_len); \n",
        "        except:\n",
        "            print(\"Found problem and skip proteins: {0}\".format(data_lst));\n",
        "    all_data = {'ID' : store_accesion_id, \n",
        "                'SEQUENCE': store_sequence_prot,\n",
        "                'length':store_seq_Length\n",
        "               }\n",
        "    return all_data; "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouEcc1pWG8uS"
      },
      "source": [
        "#**Input Protein sequences in fasta format**\n",
        "#***Note: We selected unseen portein sequences three  TRP channels and three  other channel proteins (non-TRP channels)***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6zY740bUl5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff60d60-6900-42af-81cf-8fece03e2a96"
      },
      "source": [
        "#unseen protein sequences that were not in training and testing datasets used to buitl the model\n",
        "fasta_inputs =  \">O35119_trp_channels \\\n",
        "\\nMAQFYYKRNVNAPYRDRIPLRIVRAESELSPSEKAYLNAVEKGDYASVKKSLEEAEIYFK \\\n",
        "\\nININCIDPLGRTALLIAIENENLELIELLLSFNVYVGDALLHAIRKEVVGAVELLLNHKK \\\n",
        "\\nPSGEKQVPPILLDKQFSEFTPDITPIILAAHTNNYEIIKLLVQKGVSVPRPHEVRCNCVE \\\n",
        "\\nCVSSSDVDSLRHSRSRLNIYKALASPSLIALSSEDPFLTAFQLSWELQELSKVENEFKSE \\\n",
        "\\nYEELSRQCKQFAKDLLDQTRSSRELEIILNYRDDNSLIEEQSGNDLARLKLAIKYRQKEF \\\n",
        "\\nVAQPNCQQLLASRWYDEFPGWRRRHWAVKMVTCFIIGLLFPVFSVCYLIAPKSPLGLFIR \\\n",
        "\\nKPFIKFICHTASYLTFLFLLLLASQHIDRSDLNRQGPPPTIVEWMILPWVLGFIWGEIKQ \\\n",
        "\\nMWDGGLQDYIHDWWNLMDFVMNSLYLATISLKIVAFVKYSALNPRESWDMWHPTLVAEAL \\\n",
        "\\nFAIANIFSSLRLISLFTANSHLGPLQISLGRMLLDILKFLFIYCLVLLAFANGLNQLYFY \\\n",
        "\\nYEETKGLSCKGIRCEKQNNAFSTLFETLQSLFWSIFGLINLYVTNVKAQHEFTDFVGATM \\\n",
        "\\nFGTYNVISLVVLLNMLIAMMNNSYQLIADHADIEWKFARTKLWMSYFEEGGTLPTPFNVI \\\n",
        "\\nPSPKSLWYLVKWIWTHLCKKKMRRKPESFGTIGRRAADNLRRHHQYQEVMRNLVKRYVAA \\\n",
        "\\nMIREAKTEEGLTEENVKELKQDISSFRFEVLGLLRGSKLSTIQSANAASSASSADSDEKS \\\n",
        "\\nHSEGNGKDKRKNLSLFDLTTLIHPRSAVIASERHNLSNGSALVVQEPPREKQRKVNFVAD \\\n",
        "\\nIKNFGLFHRRSKQNAAEQNANQIFSVSEEITRQQAAGALERNIQLESKGLASRGDRSIPG \\\n",
        "\\nLNEQCVLVDHRERNTDTLGLQVGKRVCSSFKSEKVVVEDTVPIIPKEKHAQEEDSSIDYD \\\n",
        "\\nLSPTDTVAHEDYVTTRL \\\n",
        ">O35119_trp_channels \\\n",
        "\\nMAQFYYKRNVNAPYRDRIPLRIVRAESELSPSEKAYLNAVEKGDYASVKKSLEEAEIYFK \\\n",
        "\\nININCIDPLGRTALLIAIENENLELIELLLSFNVYVGDALLHAIRKEVVGAVELLLNHKK \\\n",
        "\\nPSGEKQVPPILLDKQFSEFTPDITPIILAAHTNNYEIIKLLVQKGVSVPRPHEVRCNCVE \\\n",
        "\\nCVSSSDVDSLRHSRSRLNIYKALASPSLIALSSEDPFLTAFQLSWELQELSKVENEFKSE \\\n",
        "\\nYEELSRQCKQFAKDLLDQTRSSRELEIILNYRDDNSLIEEQSGNDLARLKLAIKYRQKEF \\\n",
        "\\nVAQPNCQQLLASRWYDEFPGWRRRHWAVKMVTCFIIGLLFPVFSVCYLIAPKSPLGLFIR \\\n",
        "\\nKPFIKFICHTASYLTFLFLLLLASQHIDRSDLNRQGPPPTIVEWMILPWVLGFIWGEIKQ \\\n",
        "\\nMWDGGLQDYIHDWWNLMDFVMNSLYLATISLKIVAFVKYSALNPRESWDMWHPTLVAEAL \\\n",
        "\\nFAIANIFSSLRLISLFTANSHLGPLQISLGRMLLDILKFLFIYCLVLLAFANGLNQLYFY \\\n",
        "\\nYEETKGLSCKGIRCEKQNNAFSTLFETLQSLFWSIFGLINLYVTNVKAQHEFTDFVGATM \\\n",
        "\\nFGTYNVISLVVLLNMLIAMMNNSYQLIADHADIEWKFARTKLWMSYFEEGGTLPTPFNVI \\\n",
        "\\nPSPKSLWYLVKWIWTHLCKKKMRRKPESFGTIGRRAADNLRRHHQYQEVMRNLVKRYVAA \\\n",
        "\\nMIREAKTEEGLTEENVKELKQDISSFRFEVLGLLRGSKLSTIQSANAASSASSADSDEKS \\\n",
        "\\nHSEGNGKDKRKNLSLFDLTTLIHPRSAVIASERHNLSNGSALVVQEPPREKQRKVNFVAD \\\n",
        "\\nIKNFGLFHRRSKQNAAEQNANQIFSVSEEITRQQAAGALERNIQLESKGLASRGDRSIPG \\\n",
        "\\nLNEQCVLVDHRERNTDTLGLQVGKRVCSSFKSEKVVVEDTVPIIPKEKHAQEEDSSIDYD \\\n",
        "\\nLSPTDTVAHEDYVTTRL \\\n",
        ">Q99J21_trp_channels \\\n",
        "\\nMATPAGRRASETERLLTPNPGYGTQVGTSPAPTTPTEEEDLRRRLKYFFMSPCDKFRAKG \\\n",
        "\\nRKPCKLMLQVVKILVVTVQLILFGLSNQLVVTFREENTIAFRHLFLLGYSDGSDDTFAAY \\\n",
        "\\nTQEQLYQAIFYAVDQYLILPEISLGRYAYVRGGGGPWANGSALALCQRYYHRGHVDPAND \\\n",
        "\\nTFDIDPRVVTDCIQVDPPDRPPDIPSEDLDFLDGSASYKNLTLKFHKLINVTIHFQLKTI \\\n",
        "\\nNLQSLINNEIPDCYTFSILITFDNKAHSGRIPIRLETKTHIQECKHPSVSRHGDNSFRLL \\\n",
        "\\nFDVVVILTCSLSFLLCARSLLRGFLLQNEFVVFMWRRRGREISLWERLEFVNGWYILLVT \\\n",
        "\\nSDVLTISGTVMKIGIEAKNLASYDVCSILLGTSTLLVWVGVIRYLTFFHKYNILIATLRV \\\n",
        "\\nALPSVMRFCCCVAVIYLGYCFCGWIVLGPYHVKFRSLSMVSECLFSLINGDDMFVTFAAM \\\n",
        "\\nQAQQGHSSLVWLFSQLYLYSFISLFIYMVLSLFIALITGAYDTIKHPGGTGTEKSELQAY \\\n",
        "\\nIEQCQDSPTSGKFRRGSGSACSLFCCCGRDSPEDHSLLVN \\\n",
        ">P03646_non_trp_channels \\\n",
        "\\nMFGAIAGGIASALAGGAMSKLFGGGQKAASGGIQGDVLATDNNTVGMGDAGIKSAIQGSN \\\n",
        "\\nVPNPDEAAPSFVSGAMAKAGKGLLEGTLQAGTSAVSDKLLDLVGLGGKSAADKGKDTRDY \\\n",
        "\\nLAAAFPELNAWERAGADASSAGMVDAGFENQKELTKMQLDNQKEIAEMQNETQKEIAGIQ \\\n",
        "\\nSATSRQNTKDQVYAQNEMLAYQQKESTARVASIMENTNLSKQQQVSEIMRQMLTQAQTAG \\\n",
        "\\nQYFTNDQIKEMTRKVSAEVDLVHQQTQNQRYGSSHIGATAKDISNVVTDAASGVVDIFHG \\\n",
        "\\nIDKAVADTWNNFWKDGKADGIGSNLSRK \\\n",
        ">P13583_non_trp_channels \\\n",
        "\\nMSRIKAIIASVIICIIVCLSWAVNHYRDNAITYKEQRDKATSIIADMQKRQRDVAELDAR \\\n",
        "\\nYTKELADANATIETLRADVSAGRKRLQVSATCPKSTTGASGMGDGESPRLTADAELNYYR \\\n",
        "\\nLRSGIDRITAQVNYLQEYIRSQCLK \\\n",
        ">Q6IQ69_non_trp_channels \\\n",
        "\\nMGAFIAKMLLPTISSLVFVPAASVAAKRGFHMEAMVYFFTMFFTAIYHACDGPGLSILCF \\\n",
        "\\nMKYDILEYFSVYGTAISMWVTLLALGDFDEPKRSSLTMFGVLTAAVRIYQDRLGYGIYSG \\\n",
        "\\nPIGTAVFMITVKWLQKMKEKKGLYPDKSVYTQQVGPGCCFGALALMLRFYFEEWDYAYVH \\\n",
        "\\nSFYHVSLAMSFILLLPKKNRYAGTGRNAAKLNCYTLCCCV\"\n",
        "\n",
        "\n",
        "# call functions\n",
        "get_array_fasta = read_fasta_input(fasta_inputs);\n",
        "\n",
        "\n",
        "# Store in dataframe\n",
        "df_fasta_format = pd.DataFrame(get_array_fasta) \n",
        "prot_id_test_name  = df_fasta_format['ID'].tolist()\n",
        "print(prot_id_test_name) \n",
        "\n",
        "print(df_fasta_format);\n",
        "print(\"Total fasta input: \", len(df_fasta_format.index))\n",
        "print(\"Min len test: \", min(df_fasta_format['length'].tolist()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O35119_trp_channels ', 'O35119_trp_channels ', 'Q99J21_trp_channels ', 'P03646_non_trp_channels ', 'P13583_non_trp_channels ', 'Q6IQ69_non_trp_channels ']\n",
            "                         ID  ... length\n",
            "0      O35119_trp_channels   ...    977\n",
            "1      O35119_trp_channels   ...    977\n",
            "2      Q99J21_trp_channels   ...    580\n",
            "3  P03646_non_trp_channels   ...    328\n",
            "4  P13583_non_trp_channels   ...    145\n",
            "5  Q6IQ69_non_trp_channels   ...    220\n",
            "\n",
            "[6 rows x 3 columns]\n",
            "Total fasta input:  6\n",
            "Min len test:  145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haxK5KNKIT9w"
      },
      "source": [
        "#**Call to generate representations for given protein sequences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdo15ca3WYcy",
        "outputId": "8ba65be7-b2cd-45d9-ffe8-ada09f21ed07"
      },
      "source": [
        "full_length_features_trp_channels =  generate_portionwise_embeddings(df_fasta_format)\n",
        "test_x = full_length_features_trp_channels.iloc[:,0:20480].values"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "M A Q F Y Y K R N V N A P Y R D R I P L R I V R A E S E L S P S E K A Y L N A V E K G D Y A S V K K S L E E A E I Y F K I N I N C I D P L G R T A L L I A I E N E N L E L I E L L L S F N V Y V G D A L L H A I R K E V V G A V E L L L N H K K P S G E K Q V P P I L L D K Q F S E F T P D I T P I I L A A H T N N Y E I I K L L V Q K G V S V P R P H E V R C N C V E C V S S S D V D S L R H S R S R L N I Y K A L A S P S L I A L S S E D P F L T A F Q L S W E L Q E L S K V E N E F K S E Y E E L S R Q C K Q F A K D L L D Q T R S S R E L E I I L N Y R D D N S L I E E Q S G N D L A R L K L A I K Y R Q K E F V A Q P N C Q Q L L A S R W Y D E F P G W R R R H W A V K M V T C F I I G L L F P V F S V C Y L I A P K S P L G L F I R K P F I K F I C H T A S Y L T F L F L L L L A S Q H I D R S D L N R Q G P P P T I V E W M I L P W V L G F I W G E I K Q M W D G G L Q D Y I H D W W N L M D F V M N S L Y L A T I S L K I V A F V K Y S A L N P R E S W D M W H P T L V A E A L F A I A N I F S S L R L I S L F T A N S H L G P L Q I S L G\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 18.002633333206177 seconds to extract embedding features]\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "1   -0.510162 -1.212976 -0.220211  ...  0.242540 -0.311230        m\n",
            "2   -0.470184 -0.695080  0.004464  ...  0.394761  0.214264        a\n",
            "3    0.330526 -0.107606  0.010006  ... -0.033313  0.186526        q\n",
            "4   -0.497715 -0.517126 -0.912665  ...  0.053707 -0.044824        f\n",
            "5   -0.667974 -0.696968 -0.779931  ... -0.165746 -0.296793        y\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "506  0.490665 -0.139710 -0.183285  ... -0.019186  0.418971        q\n",
            "507  0.225029 -0.390042 -0.529958  ...  0.912752  0.466573        i\n",
            "508  0.244947  0.485561 -0.097460  ...  0.704712  0.216857        s\n",
            "509 -0.139564 -0.314413 -0.082212  ...  0.434242 -0.508419        l\n",
            "510  0.616891  0.514606  0.186440  ...  0.220491 -0.319993        g\n",
            "\n",
            "[510 rows x 1025 columns]\n",
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "R M L L D I L K F L F I Y C L V L L A F A N G L N Q L Y F Y Y E E T K G L S C K G I R C E K Q N N A F S T L F E T L Q S L F W S I F G L I N L Y V T N V K A Q H E F T D F V G A T M F G T Y N V I S L V V L L N M L I A M M N N S Y Q L I A D H A D I E W K F A R T K L W M S Y F E E G G T L P T P F N V I P S P K S L W Y L V K W I W T H L C K K K M R R K P E S F G T I G R R A A D N L R R H H Q Y Q E V M R N L V K R Y V A A M I R E A K T E E G L T E E N V K E L K Q D I S S F R F E V L G L L R G S K L S T I Q S A N A A S S A S S A D S D E K S H S E G N G K D K R K N L S L F D L T T L I H P R S A V I A S E R H N L S N G S A L V V Q E P P R E K Q R K V N F V A D I K N F G L F H R R S K Q N A A E Q N A N Q I F S V S E E I T R Q Q A A G A L E R N I Q L E S K G L A S R G D R S I P G L N E Q C V L V D H R E R N T D T L G L Q V G K R V C S S F K S E K V V V E D T V P I I P K E K H A Q E E D S S I D Y D L S P T D T V A H E D Y V T T R L\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 14.897120237350464 seconds to extract embedding features]\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "1   -0.450574 -1.017052 -0.271808  ...  0.153295 -0.420125        r\n",
            "2    0.380684 -0.620585 -0.564391  ...  0.816197  0.053868        m\n",
            "3    0.055185 -0.331565 -0.336551  ...  0.843079 -0.522621        l\n",
            "4    0.086726 -0.223938 -0.384294  ...  0.873756 -0.499494        l\n",
            "5    0.842975  0.404372 -0.473677  ...  0.253504 -0.393095        d\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "463 -0.562520  0.061336 -0.133126  ...  0.155808 -0.202657        v\n",
            "464  0.342002 -0.588289  0.062047  ...  0.138319  0.428473        t\n",
            "465  0.321881 -0.491639  0.060437  ...  0.096201  0.404871        t\n",
            "466 -0.017152 -0.243908 -0.707304  ... -0.262612 -0.288742        r\n",
            "467  0.063145 -0.187494 -0.130236  ...  0.661795 -0.236818        l\n",
            "\n",
            "[467 rows x 1025 columns]\n",
            "All BERT EMBDDING BEFORE CALCULATIONS:\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "0   -0.510162 -1.212976 -0.220211  ...  0.242540 -0.311230        m\n",
            "1   -0.470184 -0.695080  0.004464  ...  0.394761  0.214264        a\n",
            "2    0.330526 -0.107606  0.010006  ... -0.033313  0.186526        q\n",
            "3   -0.497715 -0.517126 -0.912665  ...  0.053707 -0.044824        f\n",
            "4   -0.667974 -0.696968 -0.779931  ... -0.165746 -0.296793        y\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "972 -0.562520  0.061336 -0.133126  ...  0.155808 -0.202657        v\n",
            "973  0.342002 -0.588289  0.062047  ...  0.138319  0.428473        t\n",
            "974  0.321881 -0.491639  0.060437  ...  0.096201  0.404871        t\n",
            "975 -0.017152 -0.243908 -0.707304  ... -0.262612 -0.288742        r\n",
            "976  0.063145 -0.187494 -0.130236  ...  0.661795 -0.236818        l\n",
            "\n",
            "[977 rows x 1025 columns]\n",
            "   residue          0          1  ...       1021       1022       1023\n",
            "0        a  24.536371 -24.822136  ...  32.464303   7.600690 -35.359784\n",
            "1        c   5.394439   2.047164  ...   7.254885   5.239964   0.360456\n",
            "2        d  21.741876  14.867932  ...  -9.404592  10.661374 -10.645352\n",
            "3        e  -2.351029 -23.189203  ...   8.323635  -1.658068   5.970915\n",
            "4        f  -6.476485 -18.388870  ...   8.492873  24.556456   5.885508\n",
            "5        g  28.647495  26.966903  ...  13.892643  15.935012 -21.427965\n",
            "6        h   9.580966  -7.690196  ...   3.768283   0.137926   1.786989\n",
            "7        i   4.089860 -20.432064  ...  -3.699149  50.456409  16.654047\n",
            "8        k  40.056888  38.250707  ...  25.601420  34.939026  -7.156761\n",
            "9        l  -4.539979 -29.254210  ...  38.773513  61.579259 -30.314437\n",
            "10       m   2.569731  -6.149876  ...   9.155292   5.279730   0.796585\n",
            "11       n   1.119670  35.224054  ...  -7.742198 -17.385615 -26.023403\n",
            "12       p  21.344338   7.358053  ...   5.649605  11.110042 -23.308016\n",
            "13       q  18.997851  -2.781260  ...   9.394523  -2.114657  21.072884\n",
            "14       r  -0.454815   4.279665  ...  -9.604714  -7.173448 -15.781998\n",
            "15       s  11.378792  26.977105  ...  20.122214  60.283706   0.614960\n",
            "16       t   9.320583 -10.674151  ...   6.554626   3.359532  11.360185\n",
            "17       v -34.934773  14.288969  ...  62.844459  13.569232  -4.545549\n",
            "18       w   2.554928  -4.880538  ...   7.613420   5.721013  -7.827307\n",
            "19       y -10.998791 -18.080434  ...   0.433919  -0.235536  -3.726828\n",
            "\n",
            "[20 rows x 1025 columns]\n",
            "[ 24.536371 -24.822136 -33.72211  ...   0.433919  -0.235536  -3.726828]\n",
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "M A Q F Y Y K R N V N A P Y R D R I P L R I V R A E S E L S P S E K A Y L N A V E K G D Y A S V K K S L E E A E I Y F K I N I N C I D P L G R T A L L I A I E N E N L E L I E L L L S F N V Y V G D A L L H A I R K E V V G A V E L L L N H K K P S G E K Q V P P I L L D K Q F S E F T P D I T P I I L A A H T N N Y E I I K L L V Q K G V S V P R P H E V R C N C V E C V S S S D V D S L R H S R S R L N I Y K A L A S P S L I A L S S E D P F L T A F Q L S W E L Q E L S K V E N E F K S E Y E E L S R Q C K Q F A K D L L D Q T R S S R E L E I I L N Y R D D N S L I E E Q S G N D L A R L K L A I K Y R Q K E F V A Q P N C Q Q L L A S R W Y D E F P G W R R R H W A V K M V T C F I I G L L F P V F S V C Y L I A P K S P L G L F I R K P F I K F I C H T A S Y L T F L F L L L L A S Q H I D R S D L N R Q G P P P T I V E W M I L P W V L G F I W G E I K Q M W D G G L Q D Y I H D W W N L M D F V M N S L Y L A T I S L K I V A F V K Y S A L N P R E S W D M W H P T L V A E A L F A I A N I F S S L R L I S L F T A N S H L G P L Q I S L G\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 14.885794878005981 seconds to extract embedding features]\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "1   -0.510162 -1.212976 -0.220211  ...  0.242540 -0.311230        m\n",
            "2   -0.470184 -0.695080  0.004464  ...  0.394761  0.214264        a\n",
            "3    0.330526 -0.107606  0.010006  ... -0.033313  0.186526        q\n",
            "4   -0.497715 -0.517126 -0.912665  ...  0.053707 -0.044824        f\n",
            "5   -0.667974 -0.696968 -0.779931  ... -0.165746 -0.296793        y\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "506  0.490665 -0.139710 -0.183285  ... -0.019186  0.418971        q\n",
            "507  0.225029 -0.390042 -0.529958  ...  0.912752  0.466573        i\n",
            "508  0.244947  0.485561 -0.097460  ...  0.704712  0.216857        s\n",
            "509 -0.139564 -0.314413 -0.082212  ...  0.434242 -0.508419        l\n",
            "510  0.616891  0.514606  0.186440  ...  0.220491 -0.319993        g\n",
            "\n",
            "[510 rows x 1025 columns]\n",
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "R M L L D I L K F L F I Y C L V L L A F A N G L N Q L Y F Y Y E E T K G L S C K G I R C E K Q N N A F S T L F E T L Q S L F W S I F G L I N L Y V T N V K A Q H E F T D F V G A T M F G T Y N V I S L V V L L N M L I A M M N N S Y Q L I A D H A D I E W K F A R T K L W M S Y F E E G G T L P T P F N V I P S P K S L W Y L V K W I W T H L C K K K M R R K P E S F G T I G R R A A D N L R R H H Q Y Q E V M R N L V K R Y V A A M I R E A K T E E G L T E E N V K E L K Q D I S S F R F E V L G L L R G S K L S T I Q S A N A A S S A S S A D S D E K S H S E G N G K D K R K N L S L F D L T T L I H P R S A V I A S E R H N L S N G S A L V V Q E P P R E K Q R K V N F V A D I K N F G L F H R R S K Q N A A E Q N A N Q I F S V S E E I T R Q Q A A G A L E R N I Q L E S K G L A S R G D R S I P G L N E Q C V L V D H R E R N T D T L G L Q V G K R V C S S F K S E K V V V E D T V P I I P K E K H A Q E E D S S I D Y D L S P T D T V A H E D Y V T T R L\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 14.55723261833191 seconds to extract embedding features]\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "1   -0.450574 -1.017052 -0.271808  ...  0.153295 -0.420125        r\n",
            "2    0.380684 -0.620585 -0.564391  ...  0.816197  0.053868        m\n",
            "3    0.055185 -0.331565 -0.336551  ...  0.843079 -0.522621        l\n",
            "4    0.086726 -0.223938 -0.384294  ...  0.873756 -0.499494        l\n",
            "5    0.842975  0.404372 -0.473677  ...  0.253504 -0.393095        d\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "463 -0.562520  0.061336 -0.133126  ...  0.155808 -0.202657        v\n",
            "464  0.342002 -0.588289  0.062047  ...  0.138319  0.428473        t\n",
            "465  0.321881 -0.491639  0.060437  ...  0.096201  0.404871        t\n",
            "466 -0.017152 -0.243908 -0.707304  ... -0.262612 -0.288742        r\n",
            "467  0.063145 -0.187494 -0.130236  ...  0.661795 -0.236818        l\n",
            "\n",
            "[467 rows x 1025 columns]\n",
            "All BERT EMBDDING BEFORE CALCULATIONS:\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "0   -0.510162 -1.212976 -0.220211  ...  0.242540 -0.311230        m\n",
            "1   -0.470184 -0.695080  0.004464  ...  0.394761  0.214264        a\n",
            "2    0.330526 -0.107606  0.010006  ... -0.033313  0.186526        q\n",
            "3   -0.497715 -0.517126 -0.912665  ...  0.053707 -0.044824        f\n",
            "4   -0.667974 -0.696968 -0.779931  ... -0.165746 -0.296793        y\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "972 -0.562520  0.061336 -0.133126  ...  0.155808 -0.202657        v\n",
            "973  0.342002 -0.588289  0.062047  ...  0.138319  0.428473        t\n",
            "974  0.321881 -0.491639  0.060437  ...  0.096201  0.404871        t\n",
            "975 -0.017152 -0.243908 -0.707304  ... -0.262612 -0.288742        r\n",
            "976  0.063145 -0.187494 -0.130236  ...  0.661795 -0.236818        l\n",
            "\n",
            "[977 rows x 1025 columns]\n",
            "   residue          0          1  ...       1021       1022       1023\n",
            "0        a  24.536371 -24.822136  ...  32.464303   7.600690 -35.359784\n",
            "1        c   5.394439   2.047164  ...   7.254885   5.239964   0.360456\n",
            "2        d  21.741876  14.867932  ...  -9.404592  10.661374 -10.645352\n",
            "3        e  -2.351029 -23.189203  ...   8.323635  -1.658068   5.970915\n",
            "4        f  -6.476485 -18.388870  ...   8.492873  24.556456   5.885508\n",
            "5        g  28.647495  26.966903  ...  13.892643  15.935012 -21.427965\n",
            "6        h   9.580966  -7.690196  ...   3.768283   0.137926   1.786989\n",
            "7        i   4.089860 -20.432064  ...  -3.699149  50.456409  16.654047\n",
            "8        k  40.056888  38.250707  ...  25.601420  34.939026  -7.156761\n",
            "9        l  -4.539979 -29.254210  ...  38.773513  61.579259 -30.314437\n",
            "10       m   2.569731  -6.149876  ...   9.155292   5.279730   0.796585\n",
            "11       n   1.119670  35.224054  ...  -7.742198 -17.385615 -26.023403\n",
            "12       p  21.344338   7.358053  ...   5.649605  11.110042 -23.308016\n",
            "13       q  18.997851  -2.781260  ...   9.394523  -2.114657  21.072884\n",
            "14       r  -0.454815   4.279665  ...  -9.604714  -7.173448 -15.781998\n",
            "15       s  11.378792  26.977105  ...  20.122214  60.283706   0.614960\n",
            "16       t   9.320583 -10.674151  ...   6.554626   3.359532  11.360185\n",
            "17       v -34.934773  14.288969  ...  62.844459  13.569232  -4.545549\n",
            "18       w   2.554928  -4.880538  ...   7.613420   5.721013  -7.827307\n",
            "19       y -10.998791 -18.080434  ...   0.433919  -0.235536  -3.726828\n",
            "\n",
            "[20 rows x 1025 columns]\n",
            "[ 24.536371 -24.822136 -33.72211  ...   0.433919  -0.235536  -3.726828]\n",
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "M A T P A G R R A S E T E R L L T P N P G Y G T Q V G T S P A P T T P T E E E D L R R R L K Y F F M S P C D K F R A K G R K P C K L M L Q V V K I L V V T V Q L I L F G L S N Q L V V T F R E E N T I A F R H L F L L G Y S D G S D D T F A A Y T Q E Q L Y Q A I F Y A V D Q Y L I L P E I S L G R Y A Y V R G G G G P W A N G S A L A L C Q R Y Y H R G H V D P A N D T F D I D P R V V T D C I Q V D P P D R P P D I P S E D L D F L D G S A S Y K N L T L K F H K L I N V T I H F Q L K T I N L Q S L I N N E I P D C Y T F S I L I T F D N K A H S G R I P I R L E T K T H I Q E C K H P S V S R H G D N S F R L L F D V V V I L T C S L S F L L C A R S L L R G F L L Q N E F V V F M W R R R G R E I S L W E R L E F V N G W Y I L L V T S D V L T I S G T V M K I G I E A K N L A S Y D V C S I L L G T S T L L V W V G V I R Y L T F F H K Y N I L I A T L R V A L P S V M R F C C C V A V I Y L G Y C F C G W I V L G P Y H V K F R S L S M V S E C L F S L I N G D D M F V T F A A M Q A Q Q G H S S L V W L F S Q L Y L Y S F I S L F I Y M V L\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 14.8718101978302 seconds to extract embedding features]\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "1   -0.484855 -1.170863 -0.184235  ...  0.253850 -0.312678        m\n",
            "2   -0.686124 -0.426622  0.206757  ...  0.420267 -0.150836        a\n",
            "3   -0.047983 -0.505184  0.084333  ...  0.464687 -0.081962        t\n",
            "4    0.414157  0.066242 -0.364825  ...  0.300716 -0.156413        p\n",
            "5    0.191573 -0.234675 -0.116018  ...  0.432472 -0.550172        a\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "506  0.226339 -0.377101 -0.172271  ...  0.834370  0.539509        i\n",
            "507 -0.258982 -0.544695 -0.931108  ...  0.033831 -0.028500        y\n",
            "508  0.076726  0.057474  0.030093  ...  0.120821  0.242738        m\n",
            "509 -0.623122  0.103024  0.044807  ...  0.058059 -0.144893        v\n",
            "510 -0.132194 -0.188674  0.060216  ...  0.424626 -0.197227        l\n",
            "\n",
            "[510 rows x 1025 columns]\n",
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "S L F I A L I T G A Y D T I K H P G G T G T E K S E L Q A Y I E Q C Q D S P T S G K F R R G S G S A C S L F C C C G R D S P E D H S L L V N\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 12.320716857910156 seconds to extract embedding features]\n",
            "           0         1         2  ...      1022      1023  residue\n",
            "1  -0.329133 -0.937181 -0.037567  ...  0.263797 -0.388703        s\n",
            "2  -0.238228 -0.690576 -0.636217  ...  0.686514 -0.481723        l\n",
            "3   0.033856 -0.368332 -0.820718  ...  0.479622  0.129339        f\n",
            "4  -0.437432 -0.581363 -0.387013  ...  0.157360 -0.068329        i\n",
            "5   0.224824 -0.663285 -0.676455  ...  0.256769 -0.930142        a\n",
            "..       ...       ...       ...  ...       ...       ...      ...\n",
            "66  0.482978  0.035756 -0.443119  ...  0.903761 -0.344581        s\n",
            "67  0.339222 -0.350050 -0.854898  ...  0.744410 -0.111874        l\n",
            "68  0.288544 -0.264550 -0.548852  ...  0.615240 -0.281253        l\n",
            "69 -0.075006 -0.304853 -0.436686  ...  0.290554 -0.035877        v\n",
            "70 -0.000605 -0.332715  0.114196  ...  0.096004 -0.377559        n\n",
            "\n",
            "[70 rows x 1025 columns]\n",
            "All BERT EMBDDING BEFORE CALCULATIONS:\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "0   -0.484855 -1.170863 -0.184235  ...  0.253850 -0.312678        m\n",
            "1   -0.686124 -0.426622  0.206757  ...  0.420267 -0.150836        a\n",
            "2   -0.047983 -0.505184  0.084333  ...  0.464687 -0.081962        t\n",
            "3    0.414157  0.066242 -0.364825  ...  0.300716 -0.156413        p\n",
            "4    0.191573 -0.234675 -0.116018  ...  0.432472 -0.550172        a\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "575  0.482978  0.035756 -0.443119  ...  0.903761 -0.344581        s\n",
            "576  0.339222 -0.350050 -0.854898  ...  0.744410 -0.111874        l\n",
            "577  0.288544 -0.264550 -0.548852  ...  0.615240 -0.281253        l\n",
            "578 -0.075006 -0.304853 -0.436686  ...  0.290554 -0.035877        v\n",
            "579 -0.000605 -0.332715  0.114196  ...  0.096004 -0.377559        n\n",
            "\n",
            "[580 rows x 1025 columns]\n",
            "   residue          0          1  ...       1021       1022       1023\n",
            "0        a   9.212690  -9.358722  ...  15.644061   7.934737 -14.273086\n",
            "1        c   8.926444  -0.405918  ...  13.756836   8.692547   4.894479\n",
            "2        d  10.536764  12.553920  ...  -9.274467   5.383670  -9.754934\n",
            "3        e   0.457375  -1.085276  ...   3.992478   1.011869   0.924772\n",
            "4        f  -6.242023  -8.847024  ...   7.625183  16.876750   8.740257\n",
            "5        g  27.017768  25.322141  ...  11.514283  13.500082 -17.518921\n",
            "6        h   5.100325  -3.596086  ...  -0.116398  -2.114561   2.194487\n",
            "7        i   2.499360 -12.226562  ...  -5.977463  31.703517  14.976626\n",
            "8        k  17.256193  14.190602  ...   5.359167  11.530102  -0.501309\n",
            "9        l   1.300469  -7.095804  ...  17.838694  35.923139 -14.719766\n",
            "10       m   0.571745  -1.339808  ...   2.398941   2.600743   1.142255\n",
            "11       n   0.479243  13.468818  ...  -1.630223  -2.793198  -8.252566\n",
            "12       p  12.946226  11.285445  ...   6.270476   7.151819 -10.453397\n",
            "13       q  12.001656   1.874398  ...   3.713858  -1.930130  11.622119\n",
            "14       r   0.920032   7.698845  ...  -5.662676   0.802670  -6.545251\n",
            "15       s   9.901266  11.965421  ...  11.840469  36.440533   2.828051\n",
            "16       t   9.707480  -8.328606  ...   4.314150   0.355630  12.147233\n",
            "17       v -22.870569  12.167210  ...  41.979760   6.304117   0.171021\n",
            "18       w   1.445469  -1.787149  ...   3.356214   3.986980  -2.814516\n",
            "19       y -10.860430 -16.482557  ...   3.108557   1.711082  -1.259438\n",
            "\n",
            "[20 rows x 1025 columns]\n",
            "[  9.21269   -9.358722 -14.380729 ...   3.108557   1.711082  -1.259438]\n",
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "M F G A I A G G I A S A L A G G A M S K L F G G G Q K A A S G G I Q G D V L A T D N N T V G M G D A G I K S A I Q G S N V P N P D E A A P S F V S G A M A K A G K G L L E G T L Q A G T S A V S D K L L D L V G L G G K S A A D K G K D T R D Y L A A A F P E L N A W E R A G A D A S S A G M V D A G F E N Q K E L T K M Q L D N Q K E I A E M Q N E T Q K E I A G I Q S A T S R Q N T K D Q V Y A Q N E M L A Y Q Q K E S T A R V A S I M E N T N L S K Q Q Q V S E I M R Q M L T Q A Q T A G Q Y F T N D Q I K E M T R K V S A E V D L V H Q Q T Q N Q R Y G S S H I G A T A K D I S N V V T D A A S G V V D I F H G I D K A V A D T W N N F W K D G K A D G I G S N L S R K\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 13.745243549346924 seconds to extract embedding features]\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "1   -0.423576 -1.196073 -0.109972  ...  0.223175 -0.356553        m\n",
            "2   -0.089803 -0.339474 -0.696322  ...  0.877685  0.279644        f\n",
            "3    0.878880  0.399377  0.255794  ...  0.370006 -0.123857        g\n",
            "4    0.854869 -0.502359 -0.455636  ...  0.431934 -0.224199        a\n",
            "5   -0.448285 -0.530238 -0.367807  ...  0.833632  0.212574        i\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "324 -0.180630  0.817747 -0.497349  ... -0.216801 -0.702445        n\n",
            "325  0.143507 -0.216868 -0.188313  ...  0.830085 -0.291547        l\n",
            "326  0.513112  0.166364 -0.838677  ...  1.276545  0.218221        s\n",
            "327  0.275634 -0.324385 -1.552296  ...  0.427189 -0.315188        r\n",
            "328  1.250645  0.691573 -0.388489  ...  1.049039 -0.170069        k\n",
            "\n",
            "[328 rows x 1025 columns]\n",
            "All BERT EMBDDING BEFORE CALCULATIONS:\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "0   -0.423576 -1.196073 -0.109972  ...  0.223175 -0.356553        m\n",
            "1   -0.089803 -0.339474 -0.696322  ...  0.877685  0.279644        f\n",
            "2    0.878880  0.399377  0.255794  ...  0.370006 -0.123857        g\n",
            "3    0.854869 -0.502359 -0.455636  ...  0.431934 -0.224199        a\n",
            "4   -0.448285 -0.530238 -0.367807  ...  0.833632  0.212574        i\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "323 -0.180630  0.817747 -0.497349  ... -0.216801 -0.702445        n\n",
            "324  0.143507 -0.216868 -0.188313  ...  0.830085 -0.291547        l\n",
            "325  0.513112  0.166364 -0.838677  ...  1.276545  0.218221        s\n",
            "326  0.275634 -0.324385 -1.552296  ...  0.427189 -0.315188        r\n",
            "327  1.250645  0.691573 -0.388489  ...  1.049039 -0.170069        k\n",
            "\n",
            "[328 rows x 1025 columns]\n",
            "   residue          0          1  ...       1021       1022       1023\n",
            "0        a  16.723269 -17.824709  ...  20.399627  19.045056 -18.845304\n",
            "1        d   9.391532   3.185184  ...   0.061742   7.304644  -0.917918\n",
            "2        e  -0.750401  -7.028228  ...   9.799073   2.204107   2.241948\n",
            "3        f  -0.257929  -3.349602  ...   4.077745   6.458335   1.504429\n",
            "4        g  29.201170  15.815018  ...  19.374516  16.291904 -16.701891\n",
            "5        h   0.966242  -0.752086  ...   0.663617   0.557665   0.046322\n",
            "6        i  -0.222107  -4.848412  ...   0.671333  13.907917   7.610642\n",
            "7        k  13.694893  11.657789  ...  13.012139  15.233106   2.440602\n",
            "8        l   0.282473  -7.973042  ...   5.600920  10.386621  -2.942258\n",
            "9        m   1.142112  -6.143120  ...   7.021896   8.721186   1.025249\n",
            "10       n  -1.761898  11.756825  ...  -5.257711  -2.954636  -8.874809\n",
            "11       p   2.246769  -0.982626  ...   1.421704   2.503565  -2.038202\n",
            "12       q  10.760196  -0.178497  ...   9.000892   3.071722  24.296687\n",
            "13       r   0.708703  -0.913983  ...   0.476692   0.851239  -1.454228\n",
            "14       s   3.954136   3.340836  ...   9.227307  23.104472   3.811954\n",
            "15       t   3.123480  -8.567663  ...   4.863311   4.505602   8.318609\n",
            "16       v  -6.153838  -1.150280  ...  16.346903   5.889160   3.563420\n",
            "17       w   0.101006  -0.865229  ...   1.566101   2.077088  -0.060776\n",
            "18       y  -2.442406  -3.732024  ...   0.632271   0.442216  -0.086896\n",
            "\n",
            "[19 rows x 1025 columns]\n",
            "[ 16.723269 -17.824709 -19.861452 ...   0.632271   0.442216  -0.086896]\n",
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "M S R I K A I I A S V I I C I I V C L S W A V N H Y R D N A I T Y K E Q R D K A T S I I A D M Q K R Q R D V A E L D A R Y T K E L A D A N A T I E T L R A D V S A G R K R L Q V S A T C P K S T T G A S G M G D G E S P R L T A D A E L N Y Y R L R S G I D R I T A Q V N Y L Q E Y I R S Q C L K\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 12.797942399978638 seconds to extract embedding features]\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "1   -0.407396 -1.217973 -0.102570  ...  0.273654 -0.318338        m\n",
            "2    0.318121  0.029489 -0.294389  ...  0.867333 -0.438070        s\n",
            "3    0.011036 -0.272581 -0.891873  ...  0.330963 -0.403308        r\n",
            "4    0.074774 -0.371884 -0.522095  ...  0.656445 -0.010196        i\n",
            "5    0.517206  0.139271 -0.238233  ...  0.844549  0.073634        k\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "141  0.237100  0.601531 -0.623591  ...  0.825681  0.277965        s\n",
            "142  0.646637 -0.084381 -0.691030  ...  0.383229  0.891178        q\n",
            "143  0.567962 -0.145117 -0.212199  ...  0.617272 -0.059531        c\n",
            "144 -0.265828 -0.474676 -0.508894  ...  0.937252 -0.116760        l\n",
            "145  1.038385  0.836284 -0.231736  ...  0.569580 -0.110745        k\n",
            "\n",
            "[145 rows x 1025 columns]\n",
            "All BERT EMBDDING BEFORE CALCULATIONS:\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "0   -0.407396 -1.217973 -0.102570  ...  0.273654 -0.318338        m\n",
            "1    0.318121  0.029489 -0.294389  ...  0.867333 -0.438070        s\n",
            "2    0.011036 -0.272581 -0.891873  ...  0.330963 -0.403308        r\n",
            "3    0.074774 -0.371884 -0.522095  ...  0.656445 -0.010196        i\n",
            "4    0.517206  0.139271 -0.238233  ...  0.844549  0.073634        k\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "140  0.237100  0.601531 -0.623591  ...  0.825681  0.277965        s\n",
            "141  0.646637 -0.084381 -0.691030  ...  0.383229  0.891178        q\n",
            "142  0.567962 -0.145117 -0.212199  ...  0.617272 -0.059531        c\n",
            "143 -0.265828 -0.474676 -0.508894  ...  0.937252 -0.116760        l\n",
            "144  1.038385  0.836284 -0.231736  ...  0.569580 -0.110745        k\n",
            "\n",
            "[145 rows x 1025 columns]\n",
            "   residue         0         1  ...       1021      1022       1023\n",
            "0        a  9.129442 -7.717785  ...  11.475870  5.195767 -11.255799\n",
            "1        c  2.329078 -0.319847  ...   4.031005  2.387695  -0.566114\n",
            "2        d  3.864826  2.636070  ...   3.119677  2.892417  -1.715728\n",
            "3        e  0.095275 -3.608780  ...   5.316028  1.033081  -0.486809\n",
            "4        g  2.902165  1.775017  ...   4.992753  3.477567  -2.978744\n",
            "5        h  0.318500 -0.316460  ...   0.787389 -0.064993  -0.282424\n",
            "6        i -3.177833 -4.497899  ...   8.045141  8.563304   1.387346\n",
            "7        k  5.103983  3.591673  ...   5.843961  3.837585  -0.544969\n",
            "8        l -0.944017 -3.934571  ...   6.738822  5.216641  -0.891921\n",
            "9        m -0.444905 -2.775631  ...   1.018975  1.632142   0.042748\n",
            "10       n  0.306966  1.178870  ...   2.051932 -0.580774  -2.240748\n",
            "11       p  0.634134 -0.087572  ...   1.068082  1.316199  -1.457189\n",
            "12       q  4.966179 -1.128440  ...   2.791050  0.587953   4.870103\n",
            "13       r  0.371589 -2.279065  ...   2.505645 -1.741663  -3.135062\n",
            "14       s  1.926333  1.699756  ...   5.791827  9.160427   0.601371\n",
            "15       t  0.606437 -5.142130  ...   5.512885  2.421378   4.208113\n",
            "16       v -3.795344 -0.452754  ...   8.594244  0.926019   0.900731\n",
            "17       w -0.101688 -0.786297  ...   0.706898  0.562062  -0.248581\n",
            "18       y -3.447252 -5.734313  ...   2.310928  0.004467  -0.815616\n",
            "\n",
            "[19 rows x 1025 columns]\n",
            "[ 9.1294420e+00 -7.7177850e+00 -1.2221705e+01 ...  2.3109280e+00\n",
            "  4.4670000e-03 -8.1561600e-01]\n",
            ">>  BERT pretrained directory: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "SUBSEQUENCE OF PROTEINS:\n",
            "M G A F I A K M L L P T I S S L V F V P A A S V A A K R G F H M E A M V Y F F T M F F T A I Y H A C D G P G L S I L C F M K Y D I L E Y F S V Y G T A I S M W V T L L A L G D F D E P K R S S L T M F G V L T A A V R I Y Q D R L G Y G I Y S G P I G T A V F M I T V K W L Q K M K E K K G L Y P D K S V Y T Q Q V G P G C C F G A L A L M L R F Y F E E W D Y A Y V H S F Y H V S L A M S F I L L L P K K N R Y A G T G R N A A K L N C Y T L C C C V\n",
            "Bert Path: /content/model_folder/cased_L-24_H-1024_A-16\n",
            "[It takes 13.15814995765686 seconds to extract embedding features]\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "1   -0.496200 -1.232533 -0.048844  ...  0.278641 -0.329254        m\n",
            "2    0.297241  0.006774  0.015217  ...  0.607022 -0.723373        g\n",
            "3   -0.002066 -0.862093 -0.661366  ...  0.448646 -0.798508        a\n",
            "4   -0.198983 -0.802439 -0.581703  ...  0.740045 -0.101802        f\n",
            "5   -0.595505 -0.758513 -0.179857  ...  0.143721  0.113689        i\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "216 -0.258583 -0.189493 -0.390822  ...  0.540904  0.075088        l\n",
            "217  0.627808 -0.255120 -0.107620  ...  0.521021  0.240866        c\n",
            "218  0.518950 -0.441343 -0.061068  ...  0.723455  0.279580        c\n",
            "219  0.487636 -0.458719 -0.017154  ...  0.639774  0.199804        c\n",
            "220 -0.009844 -0.171594  0.685138  ...  0.278650  0.607122        v\n",
            "\n",
            "[220 rows x 1025 columns]\n",
            "All BERT EMBDDING BEFORE CALCULATIONS:\n",
            "            0         1         2  ...      1022      1023  residue\n",
            "0   -0.496200 -1.232533 -0.048844  ...  0.278641 -0.329254        m\n",
            "1    0.297241  0.006774  0.015217  ...  0.607022 -0.723373        g\n",
            "2   -0.002066 -0.862093 -0.661366  ...  0.448646 -0.798508        a\n",
            "3   -0.198983 -0.802439 -0.581703  ...  0.740045 -0.101802        f\n",
            "4   -0.595505 -0.758513 -0.179857  ...  0.143721  0.113689        i\n",
            "..        ...       ...       ...  ...       ...       ...      ...\n",
            "215 -0.258583 -0.189493 -0.390822  ...  0.540904  0.075088        l\n",
            "216  0.627808 -0.255120 -0.107620  ...  0.521021  0.240866        c\n",
            "217  0.518950 -0.441343 -0.061068  ...  0.723455  0.279580        c\n",
            "218  0.487636 -0.458719 -0.017154  ...  0.639774  0.199804        c\n",
            "219 -0.009844 -0.171594  0.685138  ...  0.278650  0.607122        v\n",
            "\n",
            "[220 rows x 1025 columns]\n",
            "   residue          0          1  ...       1021       1022       1023\n",
            "0        a   2.527074 -10.807205  ...  16.901326   6.112059 -10.681204\n",
            "1        c   4.080987  -2.541266  ...   4.852431   3.827656   0.832632\n",
            "2        d   3.711276   0.045727  ...  -1.053789   1.786223  -1.622804\n",
            "3        e  -1.232628  -2.118252  ...   2.958522   0.403603   0.687427\n",
            "4        f  -4.454753  -6.079841  ...   7.028641   5.645811   5.519735\n",
            "5        g  10.813322   7.097594  ...   9.242072   6.263395 -10.041910\n",
            "6        h   0.659270  -2.042341  ...   1.506451  -1.047009  -0.267375\n",
            "7        i  -1.887144  -6.418185  ...   2.071334   7.150229   1.837183\n",
            "8        k   5.605227   5.391967  ...   7.649428   9.200332  -3.486770\n",
            "9        l  -1.389519  -9.140090  ...  11.345611  11.898034  -3.987174\n",
            "10       m   1.093644  -7.602039  ...   7.465732   4.538641  -0.606349\n",
            "11       n   0.065028   1.834421  ...   0.516706  -0.563525  -1.118959\n",
            "12       p   2.364202  -0.814121  ...   1.641452   3.848073  -6.715125\n",
            "13       q   2.437572   0.323136  ...   1.697829  -0.673886   4.274812\n",
            "14       r   0.005347  -2.423365  ...   0.999605  -0.634827  -1.627243\n",
            "15       s   3.080721   2.107394  ...   4.262099  10.147212  -0.337318\n",
            "16       t   0.609633  -4.794936  ...   2.828686  -1.619270   3.969191\n",
            "17       v  -6.383023  -0.185518  ...  18.009718   3.567199   0.077308\n",
            "18       w   0.269990  -1.643289  ...   1.072349   1.878678  -0.384258\n",
            "19       y  -8.762403 -12.186412  ...   3.151268  -1.041114  -2.269583\n",
            "\n",
            "[20 rows x 1025 columns]\n",
            "[  2.527074 -10.807205 -11.66758  ...   3.151268  -1.041114  -2.269583]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnhBZKZ1IeDw"
      },
      "source": [
        "#**Path to the prediction model on saved on google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6zTtjLzSAh4"
      },
      "source": [
        "WorkDir = \"gdrive/My Drive/prediction_model/\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snmS9rWgIqAQ"
      },
      "source": [
        "#**Load the model to output probabilities**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DdkDMUEX2uy",
        "outputId": "e6ce765a-7a07-468d-875f-6420efe93793"
      },
      "source": [
        "# import joblib\n",
        "import pickle\n",
        "store_prob_class1 = []\n",
        "filenamemodel_1 = WorkDir+\"finalized_bert_large_cased_model.sav\"\n",
        "loaded_model_class_1 = pickle.load(open(filenamemodel_1, 'rb'))\n",
        "\n",
        "print(loaded_model_class_1.classes_);\n",
        "\n",
        "prob_class1 = loaded_model_class_1.predict_proba(test_x)\n",
        "print(prob_class1)\n",
        "\n",
        "for val in prob_class1: \n",
        "    store_prob_class1.append(val[1]);\n",
        "\n",
        "all_results = {'Fasta' : prot_id_test_name, \n",
        "                'Probability of a protein sequence to be a TRP channel': store_prob_class1\n",
        "               }\n",
        "print(all_results);"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "[[2.22210958e-01 7.77789042e-01]\n",
            " [2.22210958e-01 7.77789042e-01]\n",
            " [2.14952989e-01 7.85047011e-01]\n",
            " [9.99824259e-01 1.75741497e-04]\n",
            " [9.98098547e-01 1.90145310e-03]\n",
            " [9.80274353e-01 1.97256473e-02]]\n",
            "{'Fasta': ['O35119_trp_channels ', 'O35119_trp_channels ', 'Q99J21_trp_channels ', 'P03646_non_trp_channels ', 'P13583_non_trp_channels ', 'Q6IQ69_non_trp_channels '], 'Probability of a protein sequence to be a TRP channel': [0.7777890424589913, 0.7777890424589913, 0.7850470113943702, 0.0001757414966556819, 0.001901453104509814, 0.01972564727573773]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}